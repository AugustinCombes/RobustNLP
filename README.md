# RobustNLP
Protect NLP systems from adversarial attacks : towards safer modeling

0) Create new virtual environment (recommended) : `python3 -m venv [env_name]` > `cd [env_name]`
1) Clone the repository : `git clone https://github.com/AugustinCombes/RobustNLP.git`
2) Download source data : [download link](https://drive.google.com/u/0/uc?id=1VMiyg5Mrwwhz-156F4PH7-mTNla_CYJ1&export=download&confirm=t&uuid=c6b1d063-5b11-45ea-ae37-30d73265dc9f&at=ALgDtswyeFSb0UBrFTHNzDPxaXeL:1678289945156)
3) Move the zipped file into the cloned directory and unzip it
4) Install the used packages : `pip install -r requirements.txt`
