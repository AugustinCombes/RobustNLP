{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "dir_template = \"dataset/original/{benchmark}/{model}/{attack}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset/original/imdb/bert/bae/bert-base-uncased-imdb_bae.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pjoin(\n",
    "    dir_template.format(**dict(\n",
    "        benchmark='imdb',\n",
    "        model='bert',\n",
    "        attack='bae'\n",
    "    )),\n",
    "    \"bert-base-uncased-imdb_bae.csv\"\n",
    ")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>original_score</th>\n",
       "      <th>perturbed_score</th>\n",
       "      <th>original_output</th>\n",
       "      <th>perturbed_output</th>\n",
       "      <th>ground_truth_output</th>\n",
       "      <th>num_queries</th>\n",
       "      <th>result_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.871085</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the [[majority]] of ...</td>\n",
       "      <td>This is an example of why the [[lots]] of acti...</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.511798</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>810</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those [[moronic]] rappers,...</td>\n",
       "      <td>First of all I hate those [[other]] rappers, w...</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.742746</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>383</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.530072</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>442</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.595906</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>313</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>Although it strays away from the book a little...</td>\n",
       "      <td>Although it strays away from the book a little...</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.672632</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>437</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>I'm a fan of independent film. Dialogue driven...</td>\n",
       "      <td>I'm a fan of independent film. Dialogue driven...</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.601020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>The movie is made in a style that resembles Lo...</td>\n",
       "      <td>The movie is made in a style that resembles Lo...</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.891738</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>This movie gives you more of an idiea how Aust...</td>\n",
       "      <td>This movie gives you more of an idiea how Aust...</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.736054</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>219</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Before I start my review here is a quick lesso...</td>\n",
       "      <td>Before I start my review here is a quick lesso...</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.665443</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>382</td>\n",
       "      <td>Successful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5989 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  \\\n",
       "0     Once again Mr. Costner has dragged out a movie...   \n",
       "1     This is an example of why the [[majority]] of ...   \n",
       "2     First of all I hate those [[moronic]] rappers,...   \n",
       "3     Not even the Beatles could write songs everyon...   \n",
       "4     Brass pictures (movies is not a fitting word f...   \n",
       "...                                                 ...   \n",
       "9990  Although it strays away from the book a little...   \n",
       "9991  I'm a fan of independent film. Dialogue driven...   \n",
       "9993  The movie is made in a style that resembles Lo...   \n",
       "9995  This movie gives you more of an idiea how Aust...   \n",
       "9996  Before I start my review here is a quick lesso...   \n",
       "\n",
       "                                         perturbed_text  original_score  \\\n",
       "0     Once again Mr. Costner has dragged out a movie...        0.000241   \n",
       "1     This is an example of why the [[lots]] of acti...        0.000183   \n",
       "2     First of all I hate those [[other]] rappers, w...        0.000289   \n",
       "3     Not even the Beatles could write songs everyon...        0.000303   \n",
       "4     Brass pictures (movies is not a fitting word f...        0.000311   \n",
       "...                                                 ...             ...   \n",
       "9990  Although it strays away from the book a little...        0.001716   \n",
       "9991  I'm a fan of independent film. Dialogue driven...        0.000253   \n",
       "9993  The movie is made in a style that resembles Lo...        0.000199   \n",
       "9995  This movie gives you more of an idiea how Aust...        0.000554   \n",
       "9996  Before I start my review here is a quick lesso...        0.000759   \n",
       "\n",
       "      perturbed_score  original_output  perturbed_output  ground_truth_output  \\\n",
       "0            0.871085                0                 1                    0   \n",
       "1            0.511798                0                 1                    0   \n",
       "2            0.742746                0                 1                    0   \n",
       "3            0.530072                0                 1                    0   \n",
       "4            0.595906                0                 1                    0   \n",
       "...               ...              ...               ...                  ...   \n",
       "9990         0.672632                1                 0                    1   \n",
       "9991         0.601020                1                 0                    1   \n",
       "9993         0.891738                1                 0                    1   \n",
       "9995         0.736054                1                 0                    1   \n",
       "9996         0.665443                1                 0                    1   \n",
       "\n",
       "      num_queries result_type  \n",
       "0             203  Successful  \n",
       "1             810  Successful  \n",
       "2             383  Successful  \n",
       "3             442  Successful  \n",
       "4             313  Successful  \n",
       "...           ...         ...  \n",
       "9990          437  Successful  \n",
       "9991          256  Successful  \n",
       "9993           65  Successful  \n",
       "9995          219  Successful  \n",
       "9996          382  Successful  \n",
       "\n",
       "[5989 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path)\n",
    "df = df[df.result_type==\"Successful\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gus/Desktop/envs/nlp_project/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer, pipeline\n",
    "ref = \"textattack/bert-base-uncased-imdb\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(ref, do_lower_case=False)\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\", model=ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv = \"Once again Mr. Costner has dragged out a movie for far greater than necessary. Aside from the terrific sea rescue sequence, of which there are very few I just did not bother about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this point, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. this magic here, it was all I could do to keep from turning it off an hour in.\"\n",
    "ori = \"Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'label': 'LABEL_1', 'score': 0.8710859417915344}],\n",
       " [{'label': 'LABEL_0', 'score': 0.9997591376304626}])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(adv), classifier(ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 202]), torch.Size([1, 201]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tok, tok_adv = tokenizer(ori), tokenizer(adv)\n",
    "t, tadv = torch.tensor(tok['input_ids']), torch.tensor(tok_adv['input_ids'])\n",
    "t, tadv = t.reshape(1, -1), tadv.reshape(1, -1)\n",
    "t.shape, tadv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/bert-base-uncased-imdb were not used when initializing BertModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 768]), torch.Size([1, 768]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(ref)\n",
    "\n",
    "emb = model(t).last_hidden_state[:, 0, :]#.squeeze()\n",
    "emb_adv = model(tadv).last_hidden_state[:, 0, :]#.squeeze()\n",
    "emb.shape, emb_adv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample 10000 sentences from the imdb dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample 10000 sentences from the imdb dataset\n",
    "\n",
    "source : https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb = pd.read_csv(\"../raw_data/IMDB Dataset.csv\")\n",
    "imdb = imdb.sample(1_000, random_state=42)\n",
    "imdb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute their embedding with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/1000 [00:00<03:23,  4.90it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (772 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [02:47<00:00,  5.98it/s]\n"
     ]
    }
   ],
   "source": [
    "imdb_list = list()\n",
    "for review in tqdm(imdb.review.to_numpy().astype(str)):\n",
    "    with torch.no_grad():\n",
    "        review = torch.tensor(tokenizer(review)['input_ids']).reshape(1, -1)[:, :512]\n",
    "        imdb_list.append(\n",
    "            model(review).last_hidden_state[:, 0, :].squeeze()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_base = torch.stack(imdb_list, 0).numpy()\n",
    "imdb_base.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import KernelPCA as kPCA\n",
    "\n",
    "transformer = kPCA(n_components=2, kernel='cosine')\n",
    "imdb_pca = transformer.fit_transform(imdb_base)\n",
    "imdb_pca.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit multivariate normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(imdb_pca, axis=0)\n",
    "covariance = np.cov(imdb_pca, rowvar=False)\n",
    "\n",
    "from scipy.stats import multivariate_normal\n",
    "mvn = multivariate_normal(mean=mean, cov=covariance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare pdf to adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fb/c3y45k5d5gdbmk7pnky9y19c0000gn/T/ipykernel_17911/2567680269.py:3: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  clean_series = df.perturbed_text.str.replace('[', '').str.replace(']', '')\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:19<00:00,  5.14it/s]\n",
      "/var/folders/fb/c3y45k5d5gdbmk7pnky9y19c0000gn/T/ipykernel_17911/2567680269.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  clean_series = df.original_text.str.replace('[', '').str.replace(']', '')\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:20<00:00,  4.90it/s]\n"
     ]
    }
   ],
   "source": [
    "df = df.sample(100, random_state=42)\n",
    "adv_list = list()\n",
    "clean_series = df.perturbed_text.str.replace('[', '').str.replace(']', '')\n",
    "for review in tqdm(clean_series.to_numpy().astype(str)):\n",
    "    with torch.no_grad():\n",
    "        review = torch.tensor(tokenizer(review)['input_ids']).reshape(1, -1)[:, :512]\n",
    "        adv_list.append(\n",
    "            model(review).last_hidden_state[:, 0, :].squeeze()\n",
    "            )\n",
    "normal_list = list()\n",
    "clean_series = df.original_text.str.replace('[', '').str.replace(']', '')\n",
    "for review in tqdm(clean_series.to_numpy().astype(str)):\n",
    "    with torch.no_grad():\n",
    "        review = torch.tensor(tokenizer(review)['input_ids']).reshape(1, -1)[:, :512]\n",
    "        normal_list.append(\n",
    "            model(review).last_hidden_state[:, 0, :].squeeze()\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 768), (100, 768))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_base = torch.stack(adv_list, 0).numpy()\n",
    "normal_base = torch.stack(normal_list, 0).numpy()\n",
    "adv_base.shape, normal_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100, 2))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_pca = transformer.transform(adv_base)\n",
    "normal_pca = transformer.transform(normal_base)\n",
    "adv_pca.shape, normal_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:00<00:00, 60863.76it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 37677.90it/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [00:00<00:00, 38223.86it/s]\n"
     ]
    }
   ],
   "source": [
    "base_pdf, adv_pdf, normal_pdf = list(), list(), list()\n",
    "\n",
    "for e in tqdm(imdb_pca):\n",
    "    base_pdf.append(mvn.pdf(e))\n",
    "for e in tqdm(adv_pca):\n",
    "    adv_pdf.append(mvn.pdf(e))\n",
    "for e in tqdm(normal_pca):\n",
    "    normal_pdf.append(mvn.pdf(e))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean over the training base (independent, non-adversarial inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43824962193674216"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(base_pdf).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean over the adversarial examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2962777868854116"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(adv_pdf).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean over the original examples (dependent to previous adversarial ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4712958580312056"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(normal_pdf).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ba2f8f6288c42dfc5275e3a35b2dd3323a4d8bdac866cd1d094fb34b545a4785"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
